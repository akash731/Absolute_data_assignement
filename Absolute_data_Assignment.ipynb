{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import sklearn\n",
    "import math\n",
    "from sklearn.ensemble import VotingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Features so that every feature is on the same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    y=x*x\n",
    "    \n",
    "    y=math.sqrt(y.sum())\n",
    "    return(x/y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read_normalize_data function\n",
    "    1.Requires the path from which the data is to be fetched and numerical features that has to be scaled  \n",
    "    2.Reads the data\n",
    "    3.Fills the Nans and Null with mean value\n",
    "    4.Removes the data within 3 standard deviation using normal distribution\n",
    "    5.Normalises the data to same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_normalize_data(path,Numerical_data_dict):\n",
    "    df=pd.read_csv(path)\n",
    "    \n",
    "    for i in df.keys():\n",
    "            if(i in Numerical_data_dict):\n",
    "                df[i]=df[i].fillna(df[i].mean())\n",
    "                df=df[((df[i] - df[i].mean()) / df[i].std()).abs() < 3]\n",
    "                df[i]=normalize(df[i])\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split_Data Function\n",
    "    1.Requires the data frame,features and the target\n",
    "    2.Creates an imputer to fill Nan for categorical variable\n",
    "    3.Split data into train and test with 70% train and 30% test\n",
    "    4.Reshapes the data \n",
    "    5.Returns the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_Data(df,xaxis,yaxis):\n",
    "    xtrain, xtest ,ytrain,ytest= train_test_split(df[xaxis],df[yaxis], test_size = 0.3)\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    imp = imp.fit(xtrain)\n",
    "\n",
    "    # Impute our data, then train\n",
    "    \n",
    "    c, r = ytrain.shape\n",
    "    ytrain = np.array(ytrain).reshape(c,)\n",
    "    c, r = ytest.shape\n",
    "    ytest = np.array(ytest).reshape(c,)\n",
    "    return(xtrain,ytrain,xtest,ytest,imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_Random_Forest function\n",
    "    1.Gets train,test and imputes\n",
    "    2.creates and Random Forest\n",
    "    3.Creates a grid to search for hyper parameters for the best accuracy model using crossvalidation\n",
    "    4.Fits the train and test data\n",
    "    5.Returns the Accuracy,Roc Auc score and the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Random_Forest(X_train_imp,ytrain,xtest,ytest,imp):\n",
    "    ans=[]\n",
    "    rfc = RandomForestClassifier(n_jobs=-1) \n",
    "    param_grid1 = { \n",
    "    'n_estimators': [50,75,100],\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "\n",
    "    }\n",
    "    CV_rfc = sklearn.model_selection.GridSearchCV(estimator=rfc, param_grid=param_grid1, cv= 5)\n",
    "    CV_rfc.fit(X_train_imp, ytrain)\n",
    "    X_test_imp = imp.transform(xtest)\n",
    "    CV_rfc_y = CV_rfc.predict(X_test_imp)\n",
    "    ans.append(accuracy_score(ytest,CV_rfc_y))\n",
    "    ans.append(roc_auc_score(ytest,CV_rfc_y))\n",
    "    ans.append(sklearn.metrics.confusion_matrix(ytest,CV_rfc_y))\n",
    "    ans.append('Random Forest')\n",
    "    return(ans,CV_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_Gradient_Boosted_Tree function\n",
    "    1.Gets train,test and imputes\n",
    "    2.creates and Gradient boosted trees\n",
    "    3.Creates a grid to search for hyper parameters for the best accuracy model using crossvalidation  \n",
    "    4.Fits the train and test data\n",
    "    5.Returns the Accuracy,Roc Auc score and the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_Gradient_Boosted_Tree(X_train_imp,ytrain,xtest,ytest,imp):\n",
    "    ans=[]\n",
    "    gradient_boosted_classifier = sklearn.ensemble.GradientBoostingClassifier() \n",
    "    param_grid1 = { \n",
    "    'loss': ['deviance', 'exponential'],\n",
    "    'n_estimators':[50,75,100],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "\n",
    "    }\n",
    "    gradient_cv = sklearn.model_selection.GridSearchCV(estimator=gradient_boosted_classifier, param_grid=param_grid1, cv= 5)\n",
    "    gradient_cv.fit(X_train_imp, ytrain)\n",
    "    X_test_imp = imp.transform(xtest)\n",
    "    gradient_cv_y = gradient_cv.predict(X_test_imp)\n",
    "    ans.append(accuracy_score(ytest,gradient_cv_y))\n",
    "    ans.append(roc_auc_score(ytest,gradient_cv_y))\n",
    "    ans.append(sklearn.metrics.confusion_matrix(ytest,gradient_cv_y))\n",
    "    ans.append('Gradient descent')\n",
    "    return(ans,gradient_cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_Adaboost function\n",
    "    1.Gets train,test and imputes\n",
    "    2.creates and Gradient Adaboosted trees\n",
    "    3.Creates a grid to search for hyper parameters for the best accuracy model using crossvalidation\n",
    "    4.Fits the train and test data\n",
    "    5.Returns the Accuracy,Roc Auc score and the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_Adaboost(X_train_imp,ytrain,xtest,ytest,imp):\n",
    "    ans=[]\n",
    "    ada_boost = sklearn.ensemble.AdaBoostClassifier()\n",
    "    param_grid1 = { \n",
    "    'algorithm': ['SAMME', 'SAMME.R'],\n",
    "    'n_estimators':[50,75,100],\n",
    "\n",
    "    }\n",
    "    ada_cv = sklearn.model_selection.GridSearchCV(estimator=ada_boost, param_grid=param_grid1, cv= 5)\n",
    "    ada_cv.fit(X_train_imp, ytrain)\n",
    "    X_test_imp = imp.transform(xtest)\n",
    "    ada_cv_y = ada_cv.predict(X_test_imp)\n",
    "    ans.append(accuracy_score(ytest,ada_cv_y))\n",
    "    ans.append(roc_auc_score(ytest,ada_cv_y))\n",
    "    ans.append(sklearn.metrics.confusion_matrix(ytest,ada_cv_y))\n",
    "    ans.append('Adaboost')\n",
    "    return(ans,ada_cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_Voting_Classifier function\n",
    "    1.Gets train,test and different classifers for voting\n",
    "    2.creates voting classifier\n",
    "    3.Fits the train and test data\n",
    "    4.Returns the Accuracy,Roc Auc score and the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_Voting_Classifier(classifiers,X_train_imp,ytrain,xtest,ytest,imp):\n",
    "    ans=[]\n",
    "    Voting_classifier = VotingClassifier(estimators=classifiers, voting='soft')\n",
    "    Voting_classifier.fit(X_train_imp, ytrain)\n",
    "    X_test_imp = imp.transform(xtest)\n",
    "    Voting_classifier_y = Voting_classifier.predict(X_test_imp)\n",
    "    ans.append(accuracy_score(ytest,Voting_classifier_y))\n",
    "    ans.append(roc_auc_score(ytest,Voting_classifier_y))\n",
    "    ans.append(sklearn.metrics.confusion_matrix(ytest,Voting_classifier_y))\n",
    "    ans.append('Voting classifier')\n",
    "    return(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_Best_Classifier function\n",
    "    1.gets the dataframe,features and class feature\n",
    "    2.Calls train test split to split data\n",
    "    3.calls random forest function to get the answer and the classifier\n",
    "    4.calls gradient boosted function to get the answer and the classifier\n",
    "    5.calls adaboost boosted function to get the answer and the classifier\n",
    "    6.Calls the voting classifier with the above three classifier\n",
    "    7.Returns the best classifier with their accuracy,auc_roc,confusion matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Best_Classifier(df,xaxis,yaxis):\n",
    "    xtrain,ytrain,xtest,ytest,imp=split_Data(df=df,\n",
    "    xaxis=xaxis,\n",
    "    yaxis=yaxis\n",
    "    )\n",
    "    X_train_imp = imp.transform(xtrain)\n",
    "    ada_Ans,ada_Classifier=get_Adaboost(X_train_imp,ytrain,xtest,ytest,imp)\n",
    "    random_Ans,random_Classifier=get_Random_Forest(X_train_imp,ytrain,xtest,ytest,imp)\n",
    "    gradient_Ans,gradient_Classifier=get_Gradient_Boosted_Tree(X_train_imp,ytrain,xtest,ytest,imp)\n",
    "    voting_ans=get_Voting_Classifier([('Random', ada_Classifier), ('gradient', random_Classifier), ('ada', gradient_Classifier)],\n",
    "                                    X_train_imp,ytrain,xtest,ytest,imp\n",
    "                                    )\n",
    "    final_ans=pd.DataFrame([ada_Ans,\n",
    "                  random_Ans,\n",
    "                  gradient_Ans,\n",
    "                  voting_ans\n",
    "                 ],\n",
    "                  columns=['Accuracy','Roc','Confusion','Name'])\n",
    "    \n",
    "    return(final_ans.sort_values(by='Roc',ascending=False).head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data frame and call the best classifier with restricted and all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########\n",
      "Getting Best Model For Less Features\n",
      "   Accuracy       Roc               Confusion              Name\n",
      "2  0.896667  0.897093  [[275, 21], [41, 263]]  Gradient descent\n",
      "###########\n",
      "\n",
      "\n",
      "Best Model For All The features\n",
      "   Accuracy       Roc               Confusion           Name\n",
      "1  0.933333  0.933204  [[287, 18], [22, 273]]  Random Forest\n"
     ]
    }
   ],
   "source": [
    "df=read_normalize_data('Training Data (N=2000).csv',\n",
    "                      {'Level_of_Hemoglobin':1,\n",
    "                        'Genetic_Pedigree_Coefficient':1,\n",
    "                        'Age':1,\n",
    "                        'BMI':1,\n",
    "                        'Physical_activity':1,\n",
    "                        'salt_content_in_the_diet':1,\n",
    "                        'alcohol_consumption_per_day':1}\n",
    "                      \n",
    "                      )\n",
    "print('###########')\n",
    "print('Getting Best Model For Less Features')\n",
    "print(get_Best_Classifier(df=df,\n",
    "    xaxis=list((set(['Patient_Number', 'Blood_Pressure_Abnormality', 'Level_of_Hemoglobin','Genetic_Pedigree_Coefficient'] \n",
    "                   ))-set(['Blood_Pressure_Abnormality','Patient_Number'])),\n",
    "    yaxis=['Blood_Pressure_Abnormality']\n",
    "                   ))\n",
    "print('###########')\n",
    "print('\\n')\n",
    "print('Best Model For All The features')\n",
    "print(get_Best_Classifier(df=df,\n",
    "    xaxis=list((set(df.keys()))-set(['Blood_Pressure_Abnormality','Patient_Number'])),\n",
    "    yaxis=['Blood_Pressure_Abnormality']\n",
    "                   ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
